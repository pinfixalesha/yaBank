input {
  kafka {
    bootstrap_servers => "${KAFKA_BOOTSTRAP_SERVERS}"
    topics => ["logs-topic"]
    group_id => "logstash-group"
    consumer_threads => 1
  }
}

filter {
  grok {
    match => {
      "message" => "%{TIMESTAMP_ISO8601:timestamp} $$%{DATA:thread}$$ %{LOGLEVEL:level} %{JAVACLASS:logger}(?:$%{NUMBER:line}$)? - %{DATA:traceId}:%{DATA:spanId} $%{DATA:service_name}$ %{GREEDYDATA:message}"
    }
    tag_on_failure => ["_grokparsefailure"]
  }

  if "_grokparsefailure" in [tags] {
    mutate {
      add_tag => "failed_grok"
    }
  }

  date {
    match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
    target => "@timestamp"
  }
}

output {
  elasticsearch {
    hosts => ["${ELASTICSEARCH_HOSTS}"]
    index => "logs-%{+YYYY.MM.dd}"
    retry_on_conflict => 3
    action => "index"
  }

  stdout {
    codec => rubydebug
  }
}